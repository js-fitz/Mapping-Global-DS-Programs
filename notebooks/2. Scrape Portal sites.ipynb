{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape raw data from MastersPortal, BachelorsPortal, PhdPortal & DistancelearningPortal\n",
    "### (college degrees)\n",
    "\n",
    "These functions create an autosave directory for each website so progress is recoverable in case of an error during scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from selenium import webdriver\n",
    "flatten = lambda l: [i for s in l for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Scrape\n",
    "\n",
    "## masters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pages = 5094\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "base_url = f\"https://www.mastersportal.com/search/#q=kw-data%20science|lv-master|tc-USD&start=\"\n",
    "start = 0\n",
    "autosave_n = 0\n",
    "data = []\n",
    "for start in tqdm(range(0, 5094, 10)):\n",
    "    if start>0 and start%100==0:\n",
    "        data = pd.DataFrame(data)\n",
    "        autosave_n +=1\n",
    "        print(f'\\r{start/10}/5094 pages scraped (saving courses {start-100} – {start})', end='          ')\n",
    "        data.to_csv(f'mastersportal/scrape_{autosave_n}.csv', index=False)\n",
    "        data = []\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome()\n",
    "    url = base_url+str(start)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    container = driver.find_element('id', 'StudySearchResultsStudies')\n",
    "    courses = container.find_elements_by_class_name('InformationContainer')\n",
    "    for c in courses:\n",
    "        c_data = {}\n",
    "        c_data['course_name'] = c.find_element_by_class_name('StudyTitle').text\n",
    "        loc_dets = c.find_element_by_class_name('Location')\n",
    "        loc_dets = loc_dets.find_elements_by_tag_name('span')\n",
    "        c_data['institution'] = loc_dets[0].text\n",
    "        c_data['location'] = loc_dets[1].text\n",
    "        c_data['description'] = c.find_element_by_class_name('Description').text\n",
    "        right_info = c.find_element_by_class_name('InformationRight')\n",
    "        right_info = right_info.find_elements_by_tag_name('span')\n",
    "        c_data['cost'] = right_info[0].text\n",
    "        dur = right_info[1]\n",
    "        c_data['dur_period'] = dur.get_attribute('data-period')\n",
    "        c_data['dur_number'] = dur.get_attribute('data-duration')\n",
    "        extra = c.find_element_by_class_name('ExtraFacts')\n",
    "        extras = extra.find_elements_by_tag_name('span') # extra_n is a value for an unkown feature \n",
    "        for i, e in enumerate(extras):\n",
    "            c_data[f'extra_{i}'] = e.text\n",
    "        data.append(c_data) \n",
    "driver.quit()\n",
    "data = pd.DataFrame(data)\n",
    "autosave_n +=1\n",
    "print(f'\\rCompleted!\\nScraped 5094 pages ({len(data)} courses)')\n",
    "data.to_csv(f'mastersportal/scrape_{autosave_n}.csv', index=False)\n",
    "print('File saved to mastersportal/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bachelors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "base_url = f\"https://www.bachelorsportal.com/search/#q=kw-data%20science|lv-bachelor|tc-EUR&start=\"\n",
    "start = 0\n",
    "autosave_n = 0\n",
    "\n",
    "data = []\n",
    "for start in tqdm(range(0, 5713, 10)):\n",
    "    if start>0 and start%100==0:\n",
    "        data = pd.DataFrame(data)\n",
    "        autosave_n +=1\n",
    "        print(f'Saving {start-100} – {start}')\n",
    "        data.to_csv(f'bachelorsportal/scrape_{autosave_n}.csv', index=False)\n",
    "        data = []\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome()\n",
    "    url = base_url+str(start)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    container = driver.find_element('id', 'StudySearchResultsStudies')\n",
    "    courses = container.find_elements_by_class_name('InformationContainer')\n",
    "    tries = 0\n",
    "    success = False\n",
    "    while tries<3:\n",
    "        tries+=1\n",
    "        if success==True: break \n",
    "        try:\n",
    "            for c in courses:\n",
    "                c_data = {}\n",
    "                c_data['course_name'] = c.find_element_by_class_name('StudyTitle').text\n",
    "                loc_dets = c.find_element_by_class_name('Location')\n",
    "                loc_dets = loc_dets.find_elements_by_tag_name('span')\n",
    "                c_data['institution'] = loc_dets[0].text\n",
    "                c_data['location'] = loc_dets[1].text\n",
    "                c_data['description'] = c.find_element_by_class_name('Description').text\n",
    "                right_info = c.find_element_by_class_name('InformationRight')\n",
    "                right_info = right_info.find_elements_by_tag_name('span')\n",
    "                c_data['cost'] = right_info[0].text\n",
    "                dur = right_info[1]\n",
    "                c_data['dur_period'] = dur.get_attribute('data-period')\n",
    "                c_data['dur_number'] = dur.get_attribute('data-duration')\n",
    "                extra = c.find_element_by_class_name('ExtraFacts')\n",
    "                extras = extra.find_elements_by_tag_name('span')\n",
    "                for i, e in enumerate(extras):\n",
    "                    c_data[f'extra_{i}'] = e.text\n",
    "                data.append(c_data) \n",
    "                success = True\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "driver.quit()\n",
    "data = pd.DataFrame(data)\n",
    "autosave_n +=1\n",
    "print(f'Saving {start-100} – {start}')\n",
    "data.to_csv(f'bachelorsportal/scrape_{autosave_n}.csv', index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phd portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "base_url = f\"https://www.phdportal.com/search/#q=kw-data%20science|lv-phd|tc-USD&start=\"\n",
    "start = 0\n",
    "autosave_n = 0\n",
    "\n",
    "data = []\n",
    "for start in tqdm(range(0, 358, 10)):\n",
    "    if start>0 and start%100==0:\n",
    "        data = pd.DataFrame(data)\n",
    "        autosave_n +=1\n",
    "        print(f'Saving {start-100} – {start}')\n",
    "        data.to_csv(f'phdportal/scrape_{autosave_n}.csv', index=False)\n",
    "        data = []\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome()\n",
    "    url = base_url+str(start)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    container = driver.find_element('id', 'StudySearchResultsStudies')\n",
    "    courses = container.find_elements_by_class_name('InformationContainer')\n",
    "    tries = 0\n",
    "    success = False\n",
    "    while tries<3:\n",
    "        tries+=1\n",
    "        if success==True: break \n",
    "        try:\n",
    "            for c in courses:\n",
    "                c_data = {}\n",
    "                c_data['course_name'] = c.find_element_by_class_name('StudyTitle').text\n",
    "                loc_dets = c.find_element_by_class_name('Location')\n",
    "                loc_dets = loc_dets.find_elements_by_tag_name('span')\n",
    "                c_data['institution'] = loc_dets[0].text\n",
    "                c_data['location'] = loc_dets[1].text\n",
    "                c_data['description'] = c.find_element_by_class_name('Description').text\n",
    "                right_info = c.find_element_by_class_name('InformationRight')\n",
    "                right_info = right_info.find_elements_by_tag_name('span')\n",
    "                c_data['cost'] = right_info[0].text\n",
    "                dur = right_info[1]\n",
    "                c_data['dur_period'] = dur.get_attribute('data-period')\n",
    "                c_data['dur_number'] = dur.get_attribute('data-duration')\n",
    "                extra = c.find_element_by_class_name('ExtraFacts')\n",
    "                extras = extra.find_elements_by_tag_name('span')\n",
    "                for i, e in enumerate(extras):\n",
    "                    c_data[f'extra_{i}'] = e.text\n",
    "                data.append(c_data) \n",
    "                success = True\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "driver.quit()\n",
    "data = pd.DataFrame(data)\n",
    "autosave_n +=1\n",
    "print(f'Saving {start-100} – {start}')\n",
    "data.to_csv(f'phdportal/scrape_{autosave_n}.csv', index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distancelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "base_url = f\"https://www.distancelearningportal.com/search/#q=kw-data%20science|mh-blended,online|tc-EUR&start=\"\n",
    "start = 0\n",
    "\n",
    "data = []\n",
    "for start in tqdm(range(0, 21, 10)):\n",
    "    url = base_url+str(start)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    container = driver.find_element('id', 'StudySearchResultsStudies')\n",
    "    courses = container.find_elements_by_class_name('InformationContainer')\n",
    "    tries = 0\n",
    "    success = False\n",
    "    while tries<3:\n",
    "        tries+=1\n",
    "        if success==True: break \n",
    "        try:\n",
    "            for c in courses:\n",
    "                c_data = {}\n",
    "                c_data['course_name'] = c.find_element_by_class_name('StudyTitle').text\n",
    "                loc_dets = c.find_element_by_class_name('Location')\n",
    "                loc_dets = loc_dets.find_elements_by_tag_name('span')\n",
    "                c_data['institution'] = loc_dets[0].text\n",
    "                c_data['location'] = loc_dets[1].text\n",
    "                c_data['description'] = c.find_element_by_class_name('Description').text\n",
    "                right_info = c.find_element_by_class_name('InformationRight')\n",
    "                right_info = right_info.find_elements_by_tag_name('span')\n",
    "                c_data['cost'] = right_info[0].text\n",
    "                dur = right_info[1]\n",
    "                c_data['dur_period'] = dur.get_attribute('data-period')\n",
    "                c_data['dur_number'] = dur.get_attribute('data-duration')\n",
    "                extra = c.find_element_by_class_name('ExtraFacts')\n",
    "                extras = extra.find_elements_by_tag_name('span')\n",
    "                for i, e in enumerate(extras):\n",
    "                    c_data[f'extra_{i}'] = e.text\n",
    "                data.append(c_data) \n",
    "                success = True\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "driver.quit()\n",
    "degrees = pd.DataFrame(data)\n",
    "degrees.to_csv('scraped_mastersportal.csv', index=False)\n",
    "'Done... saved.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Clean & Save\n",
    "\n",
    "### combine autosave data from all websites into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = zip([\"Bachelor's\", \"Master's\", \"Ph.D.\"],\n",
    "           ['bachelorsportal', 'mastersportal', 'phdportal'])\n",
    "\n",
    "out= pd.DataFrame()\n",
    "for n, d in dirs:\n",
    "    d_data = pd.DataFrame()\n",
    "    for f in os.listdir(d):\n",
    "        d_data = pd.concat([d_data,\n",
    "                            pd.read_csv(f'{d}/{f}')],\n",
    "                          sort=False)\n",
    "    d_data['class'] = n\n",
    "    out = pd.concat([out, d_data], sort=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop probable false positives (non–DS programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_words = ['informat', 'proba', 'data', 'machine', 'geospat', \n",
    "             'analy', 'stat', 'artificial', 'intelligence', 'language']\n",
    "\n",
    "out = out.reset_index(drop=True)\n",
    "keep = []\n",
    "for i, cn in enumerate(out.course_name):\n",
    "    if any(w in cn.lower() for w in hot_words):\n",
    "        keep.append(i)\n",
    "        \n",
    "out = out.loc[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a copy...\n",
    "df = out\n",
    "\n",
    "# shift columns if degree is missing\n",
    "no_degree = df[df['extra_0'].str.contains('-time')].copy() # extra_0 skips to 'enrollment'\n",
    "df.loc[no_degree.index, 'extra_2'] = no_degree['extra_1']\n",
    "df.loc[no_degree.index, 'extra_1'] = no_degree['extra_0']\n",
    "df.loc[no_degree.index, 'extra_0'] = '(?)' # unkown degree\n",
    "\n",
    "\n",
    "# list all unknown columns (scattered values)  \n",
    "e_cols = [e for e in df.columns if 'extra' in e]\n",
    "\n",
    "\n",
    "for ridx in df.index: # iterate through courses (rows)\n",
    "    row = df.loc[ridx] \n",
    "    \n",
    "    # defaults:\n",
    "    online='No' \n",
    "    blended='No' \n",
    "    enrollment = []\n",
    "    \n",
    "    # rules for all unknown values\n",
    "    for col in e_cols: \n",
    "        val = row[col]\n",
    "        if 'time' in str(val): enrollment.append(val)\n",
    "        if 'online' in str(val).lower(): online = 'Yes'\n",
    "        if 'blended' in str(val).lower(): online = 'Blended'\n",
    "            \n",
    "    # set column names\n",
    "    df['degree'] = df['extra_0'].copy()    \n",
    "    df.loc[ridx, 'enrollment'] = ' & '.join(enrollment)\n",
    "    df.loc[ridx, 'online'] = online\n",
    "    df.loc[ridx, 'in_person'] = online\n",
    "    df.loc[ridx, 'blended_learning'] = blended\n",
    "\n",
    "mp = df.drop(columns=e_cols)\n",
    "    \n",
    "mp.drop_duplicates(inplace=True)\n",
    "mp.to_csv('portal_data.csv', index=False)\n",
    "print('file saved.')\n",
    "    \n",
    "print(mp.shape)\n",
    "mp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
