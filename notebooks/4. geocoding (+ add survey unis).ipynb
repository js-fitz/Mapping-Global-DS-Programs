{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import folium\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='•••••••@••••••.com')\n",
    "flatten = lambda l: [i for s in l for i in s]\n",
    "\n",
    "import googlemaps as gmaps\n",
    "gmaps = gmaps.Client(key='•••••••••••••••••••••••••••••••••••••••')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = pd.read_csv('scraped_coursereport.csv')\n",
    "portal = pd.read_csv('portal_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add survey data to degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv('SurveyHero-Responses-249227.csv')\n",
    "\n",
    "for ridx in survey.index:\n",
    "    row = survey.loc[ridx]\n",
    "    degrees = []\n",
    "    if row[\"Master's\"]=='x': degrees+= [\"Masters\"]\n",
    "    if row[\"Bachelor\"]=='x': degrees+= [\"Bachelor's\"]\n",
    "    if row[\"PhD\"]=='x': degrees += [\"Ph.D.\"]\n",
    "    survey.loc[ridx, 'class'] = ' / '.join(degrees)\n",
    "\n",
    "survey = survey.rename(columns={\n",
    "    'Institution/Organization:':'institution',\n",
    "    'Program/Track name:':'course_name',\n",
    "    'Location:.1': 'location'})\n",
    "survey = survey[['institution', 'course_name', 'location', 'class']].dropna(subset=['institution']).iloc[:-2]\n",
    "\n",
    "\n",
    "# combine Portal data with survey data\n",
    "degs = pd.concat([portal, survey], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geocode Portal data\n",
    "\n",
    "**(Using Google API because colleges & universities are often accurately located in Google maps)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs['geo_search'] = degs['institution'] + ', ' + degs['location'].fillna('')\n",
    "\n",
    "def get_gmap_geos(locations, max_errors=1e9):\n",
    "    failed = []\n",
    "    geocoded = {}\n",
    "    start_time = time.perf_counter()\n",
    "    errors = 0\n",
    "    for iteration, location in enumerate(locations):\n",
    "        try:\n",
    "            geocoded[location] = gmaps.geocode(location)\n",
    "            time.sleep(.05) # <-- throttle\n",
    "        except:\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                geocoded[location] = gmaps.geocode(location)\n",
    "            except:\n",
    "                geocoded[location] = ''\n",
    "                print('error at:', location)\n",
    "                errors+=1\n",
    "                failed.append(location)\n",
    "        if max_errors and max_errors==errors:\n",
    "            print('stopped at', iteration, '(max errors reached)')\n",
    "            break\n",
    "            return geocoded\n",
    "        now = time.strftime('%H:%M:%S', time.localtime(time.time()))\n",
    "        print(f'\\r{now} | {iteration}/{len(locations)} locations geocoded ({round(iteration/len(locations)*100, 2)}%) | {errors} total errors', end='')\n",
    "    print(f'\\njob completed in {time.perf_counter() - start_time}s\\n{errors} requests timed out')\n",
    "    print(len([v for v in geocoded.values() if v=='error']), 'locations not found')\n",
    "    return geocoded, failed\n",
    "\n",
    "def gmap_gcoder(df):\n",
    "    locations = set(df['geo_search'])\n",
    "\n",
    "    geocoded, failed = get_gmap_geos(locations)\n",
    "\n",
    "    df['gmaps_info'] = df['geo_search'].apply(lambda x: geocoded[x]) # map results onto back to df\n",
    "\n",
    "    def extract_coords(geo):\n",
    "        try:\n",
    "            geo = geo[-1] # drop generalized extra results\n",
    "            return geo['geometry']['location']['lat'], geo['geometry']['location']['lng']\n",
    "        except:\n",
    "            return np.nan, np.nan\n",
    "\n",
    "    df['coord'] = df['gmaps_info'].apply(extract_coords)\n",
    "    df['latitude'] = df['coord'].apply(lambda x: x[0])\n",
    "    df['longitude'] = df['coord'].apply(lambda x: x[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE GEOCODER - will take 10-15 minutes\n",
    "\n",
    "degs_gcoded = gmap_gcoder(degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_gcoded = degs_gcoded[~degs_gcoded.loc[:, :'description'].duplicated()]\n",
    "degs_gcoded.to_csv('degs_gcoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: more data (from online) is added to `mp_gcoded` (in Notebook 1.5) before mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## format & geocode Bootcamp (CourseReport) data\n",
    "\n",
    "explode rows by city & geocode with Nominatim:\n",
    "\n",
    "**(Using Nominatim because bootcamps often don't show up in Google Maps so the longer search time is is not worth it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_split(df, l_feat, multi_locs=True):\n",
    "    if multi_locs:\n",
    "        locs = set(flatten(df[l_feat].str.split(', ')))\n",
    "    else:\n",
    "        locs = set(df[l_feat])\n",
    "\n",
    "    loc_geos = {}\n",
    "    for l in tqdm(locs):\n",
    "        l = l.split('(')[0] # messy but quick to write\n",
    "        sleep_time = .25 #init\n",
    "        max_tries = 4\n",
    "        while True:\n",
    "            if max_tries <= 0:\n",
    "                print('TIMEOUT: Error at', l)\n",
    "                break\n",
    "            try:\n",
    "                time.sleep(sleep_time)\n",
    "                sleep_time  *= 2 # double wait time in each retry \n",
    "                gc = geolocator.geocode(l) \n",
    "                geo = (gc.latitude, gc.longitude)\n",
    "                loc_geos[l] = geo\n",
    "                break\n",
    "            except:\n",
    "                max_tries-=1\n",
    "\n",
    "    indi_locs = []\n",
    "    for r_idx in df.index:\n",
    "        d_row = df.loc[r_idx]\n",
    "        if multi_locs:\n",
    "            for loc in d_row[l_feat].split(', '):\n",
    "                if loc!='-' and loc.lower()!='online':\n",
    "                    new_row = d_row.copy()\n",
    "                    new_row[l_feat] = loc\n",
    "                    new_row['latitude'] = loc_geos[loc][0]\n",
    "                    new_row['longitude'] = loc_geos[loc][1]\n",
    "                    indi_locs.append(new_row)\n",
    "        else:\n",
    "            try:\n",
    "                loc = d_row[l_feat].split('(')[0]\n",
    "                if loc!='-' and loc.lower()!='online' and loc!='Multiple locations':\n",
    "                    new_row = d_row.copy()\n",
    "                    new_row[l_feat] = loc\n",
    "                    new_row['latitude'] = loc_geos[loc][0]\n",
    "                    new_row['longitude'] = loc_geos[loc][1]\n",
    "                    indi_locs.append(new_row)\n",
    "            except: print('error at', d_row)\n",
    "    return pd.DataFrame(indi_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_gcoded = geo_split(cr, 'Location')\n",
    "boot_locs.to_csv('boot_locs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
